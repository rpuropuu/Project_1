![](https://img.shields.io/badge/Python-3.9-blue)
![](https://img.shields.io/badge/tensorflow-2.4.1-blue)
![](https://img.shields.io/badge/NumPy-1.19.5-blue)
![](https://img.shields.io/badge/matplotlib-3.2.2-blue)
![](https://img.shields.io/badge/cv2-4.1.2-blue)
![](https://img.shields.io/badge/scikit-0.22.2.post1-blue)


__________


Пример построения свёрточной нейронной сети. Задача которой - локализация двух животных. Из соображений этики, полное условие задания не публикуется. Здесь будет описан только процесс получения рабочего результата. Все файлы будут доступны в пронумерованном порядке.


_________


### ПЛАН
1. Обучение нейросети различать два класса.
    - исследование вводных данных
    - поиск методов достижения результата исходя из заданных условий (малая выборка)
    - подготовка скриптов для обработки данных
2. Сохранение для последующего дообучения.
    - нюансы совместимости сетей
3. Обучение второй нейросети по предобученным моделям
    - подбор методов оптимизации для конвеерного тестирования стратегий
    - Transfer Learning c VGG16
    - Transfer Learning cо своей обученной нейронной сетью в п. 1
4. Обзор статистики
    - создание дополнительных скриптов вывода обработанных данных
    - проведение требуемых замеров для отчёта
5. Оформление
    - подготовка изображений с информацией
    - составление пайплайна
    - README-файл на гитхабе

________


1. В датасете оказалось всего **3385** изображений, который были разделены на два класса с большой разницей в соотношении: **1037** изборажений кошек и **2348** изображений собак. Всё это ещё было разбито на **80%** обучения и **20%** валидации рандомным скриптом - **2708** против **677**. А для тестовой выборки я загружал файлы из интернета. При добавлении дополнительных опций в слои аугментации, неросеть начинала показывать результаты ещё хуже. Различные придуманные мной варианты не приводили к особой стабилизации процесса обучения, уже потом, после того, когда я полностью всю сеть доделал через VGG, я вернулся к этому варианту. выкачал из интернета датасет на кошек и собак, и дополнил оба класса до **4 000 штук в каждом**. Наилучшим результатом первого поколения стал результат с **89%**, однако, он оказался не совместим со второй частью нейронной сети. Сейчас удалось переделать и обучиться на **86%**. И уже с этой моделью я обучал вторую часть нейронки искать лица животных. Этот вариант превосходит первый по определению класса, и работает на порядок быстрее, чем c VGG, но уступает в точности отрисовки боксов. _Я планирую разметить боксами обновленный датасэт и уже на нём продолжать дальнейшие эксперементы по оптимизации, ввиду ограниченности сроков выполнения задания._
2. Почти все задания на каггле, и не только тут, решаются через бинарную архитектуру, соответственно вывод подготавливается сигмоидальной функцией. Однако, для возможности классифицировать объекты, даже если их всего два, необходимо уже использовать категориальную кросэнтропию с возможностью вывода через софтамакс на два нейрона, что позволит совместить обучаемость со второй частю нейронной сети.
3. К выбору архитектуры второй нейросети я уже подходил более осознанно. Я понимал, что желательно наличие какго-либо конфига, для возможности быстрого переключения между стратегиями, а также системой логов. Решил сразу привыкать к удобному управлению через, _а вдруг Линукс_. Судя по тенденциям в сообществе, профилактика использования Transfer Learning приветствуется, а значит и используемая архитектура должна быть максимально близка к модульности, даже в пространстве понимания новчика.
4. 
