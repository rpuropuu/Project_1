![](https://img.shields.io/badge/Python-3.9-blue)
![](https://img.shields.io/badge/tensorflow-2.4.1-blue)
![](https://img.shields.io/badge/NumPy-1.19.5-blue)
![](https://img.shields.io/badge/matplotlib-3.2.2-blue)
![](https://img.shields.io/badge/cv2-4.1.2-blue)
![](https://img.shields.io/badge/scikit-0.22.2.post1-blue)


__________


После дополнения условия первичного задания (изменён ввод данных), я перезапустил обучение обеих нейронок. Вариант с использованием VGG делать не стал, как оказалось, у него итоговый коэфициент классификации обеъекта был ниже: **91%** против **97%** на своей предобученной. Для обучения использовались те же файлы, что и в первичном задании: [01_catog.ipynb](https://github.com/rpuropuu/Project_1/blob/main/first_try/01_catog.ipynb) и [02_catog.ipynb](https://github.com/rpuropuu/Project_1/blob/main/first_try/02_catog.ipynb)


_________


Новый датасет содержал тех же **3385** картинок, только теперь был заранее разбит на обучающую и валидационную выборки: **2985** + **400**. Скрипт на рандомное разделение теперь оказался не нужен - меньше работы). Предыдущий самостоятельно дополненный вариант выборки, на **8000** картинок с выравниванием соотношений классов 1 к 1, изначально обучился на **86%** и при дообучении показал **лучший результат - 91%**. Вариант сети с новой недополненной выборкой повёл себя несколько неожиданно для меня: первая сеть обучилась на тех же **86%**, а вот во второй показатель вырос с 91% **до 97%**! Да и к тому же обучалась заметно быстрее. Я даже сократил количество эпох до **5** (ранее было 15) Теперь настало время визуализировать разницу, ведь коробки обучилис на **70%** вместо **80%** ранее заявленных генератором. По факту средний коэфициент mIoU был итого ниже - 57%.


